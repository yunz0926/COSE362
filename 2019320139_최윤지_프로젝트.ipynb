{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2019320139_최윤지_프로젝트.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **기말 프로젝트 보고서**\n",
        "**2019320139 최윤지**\n",
        "\n"
      ],
      "metadata": {
        "id": "mTsQpUSJBUr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. 실험 개요** \n",
        "</br>\n",
        "\n",
        "본 실험은 고객의 Bank Marketing에 대한 데이터를 가지고 고객이 정기예금에 가입할 것인지를 예측하는 Classification 모델을 설계하는 것이다. \n",
        "</br>\n",
        "\n",
        "모델의 경우,\n",
        "\n",
        "> 1) Deicision Tree  \n",
        "2) Random Forest  \n",
        "3) MLP  \n",
        "4) KNN  \n",
        "5) Adaboost\n",
        "\n",
        "</br>\n",
        "\n",
        "다음과 같이 총 5개를 적용해보았으며, 각각의 알고리즘에 대해 파라미터를 조정하여 여러개의 모델을 만들고, cross-validation score 값을 사용하여 그 중 최적의 모델을 선정하였다. 선정 된 모델을 가지고 test-set을 이용한 결과를 분석해보고, feature selection을 적용한 후에는 어떤 성능 차이를 보이는지도 실험해보았다.  \n",
        "결론적으로 Bank Marketing의 데이터에 대해 어떤 알고리즘, 어떤 파라미터를 적용한 모델이 가장 좋은 성능을 보였는지 확인하고 그 결과를 분석해볼 것이다.\n",
        "\n",
        "</br>\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KH7nIJ-gYPXB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. 데이터 선정** \n",
        "\n",
        "</br>\n",
        "\n",
        "### **데이터 설명**\n",
        "\n",
        "실험에 사용 된 데이터는 UCI Machine Learning Repository 에서 가져온 Bank Marketing Data이다. \n",
        "(http://archive.ics.uci.edu/ml/datasets/Bank+Marketing)\n",
        "\n",
        "해당 데이터의 경우 classification을 통해 예측할만한 label 값이 잘 드러나 있어서 선정하게 되었으며, 데이터의 attribute은 다음과 같이 총 16개이다.\n",
        "</br>\n",
        "\n",
        "\n",
        "1.  **age (나이)**: numeric\n",
        "2.  **job (직업)**:  categorical ('admin.', 'blue-collar', 'entrepreneur', 'housemaid', 'management', 'retired', 'self-employed', 'services', 'student', 'technician', 'unemployed')\n",
        "3. **marital(결혼 상태)**: categorical ('divorced', 'married', 'single')\n",
        "4. **education(교육 수준)**: categorical ('basic.4y', 'basic.6y', 'basic.9y', 'high.school', 'illiterate', 'professional.course', 'university.degree', 'unknown')\n",
        "5. **default(채무불이행 여부)**: categorical ('yes', 'no')\n",
        "6. **balance(잔고)**: numeric\n",
        "7. **housing(주택 대출 유무)**: cateogorical ('yes', 'no')\n",
        "8. **loan(개인 대출 유무)**: categorical ('yes', 'no')\n",
        "9. **contact(연락처 종류)**: cateogorical('cellular', 'telephone')\n",
        "10. **month(마지막으로 연락한 달)**: categorical('jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
        "11. **day_of_week(마지막으로 연락한 요일)**: categorical('mon','tue','wed','thu','fri')\n",
        "12. **duration(마지막 연락의 지속시간)**: numeric\n",
        "13. **campaign(이 캠페인에 대해 해당 고객에게 한 연락의 수)**: numeric\n",
        "14. **pdays(지난 연락 이후 시간)**: numeric\n",
        "15. **previous(이 캠페인 이전에 해당 고객에게 한 연락의 수)**: numeric\n",
        "16. **poutcome(이전 마케팅 캠페인의 결과)**: categorical( 'failure', 'nonexistent', 'success')\n",
        "\n",
        "</br>\n",
        "\n",
        "\n",
        "17.   **y(해당 고객이 정기예금을 드는지의 여부)**: binary ('yes', 'no')\n",
        "\n",
        "</br></br>\n",
        "이 데이터 셋을 다음과 같이 깃허브를 통해 구분자 ';'로 불러왔다. \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ROLsE7-Odp1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_url = \"https://raw.githubusercontent.com/yunz0926/COSE362/master/BankMarketingData.csv\"\n",
        "\n",
        "data = pd.read_csv(data_url, sep=';')\n",
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgZG8P05BgTU",
        "outputId": "8b7f2c0e-5a67-4c2f-a3a3-c2fd67aef482"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
              "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
              "       'previous', 'poutcome', 'y'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "해당 데이터셋을 분석해본 결과, education, contact, poutcome, marital attribute에서 unknown 값이 자주 출현했는데 이 값은 NA로 비슷하게 거의 의미가 없어 모델의 성능에 좋지 않은 영향을 미칠 것이라고 생각하였다. 따라서 다음과 같이 'unknown' 값을 가진 instance들은 데이터 셋에서 제거하였다."
      ],
      "metadata": {
        "id": "IHvi36Qjl-7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[data.education != 'unknown']\n",
        "data = data[data.contact != 'unknown']\n",
        "data = data[data.poutcome != 'unknown']\n",
        "data = data[data.marital != 'unknown']\n",
        "\n",
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJCCrAvdcgYo",
        "outputId": "3cfe85e5-3f6d-4634-ac52-a530c74d4ea7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
              "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
              "       'previous', 'poutcome', 'y'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **데이터 전처리**\n",
        "선정 된 데이터 셋에는 범주형 데이터가 많이 포함되어있다. 따라서 sklearn.preprocessing 라이브러리의 LabelEnconder를 사용하여 범주형 attribute들을 수치형으로 변환해주었고, NA 값을 갖는 attribute이 있는지 확인해주었다."
      ],
      "metadata": {
        "id": "Syufpo-TmvZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "data.job = le.fit_transform(data.job)\n",
        "data.marital = le.fit_transform(data.marital)\n",
        "data.education = le.fit_transform(data.education)\n",
        "data.default = le.fit_transform(data.default)\n",
        "data.housing = le.fit_transform(data.housing)\n",
        "data.loan = le.fit_transform(data.loan)\n",
        "data.contact = le.fit_transform(data.contact)\n",
        "data.month = le.fit_transform(data.month)\n",
        "data.poutcome = le.fit_transform(data.poutcome)\n",
        "data.y = le.fit_transform(data.y)\n",
        "\n",
        "data.isna().any()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h85w1x_9ab_e",
        "outputId": "cf1cdcaf-212b-49c7-8e94-e5b660586c4f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age          False\n",
              "job          False\n",
              "marital      False\n",
              "education    False\n",
              "default      False\n",
              "balance      False\n",
              "housing      False\n",
              "loan         False\n",
              "contact      False\n",
              "day          False\n",
              "month        False\n",
              "duration     False\n",
              "campaign     False\n",
              "pdays        False\n",
              "previous     False\n",
              "poutcome     False\n",
              "y            False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **데이터셋 분리**\n",
        "다음과 같이 feature 변수 x와 label 변수 y를 지정해주고, train_test_split을 이용하여 7:3의 비율로 train data와 test data를 나누었다."
      ],
      "metadata": {
        "id": "6oJ8O65ynshl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "y = data['y']\n",
        "x = data.drop(columns=['y'])\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42, shuffle=True)"
      ],
      "metadata": {
        "id": "0lEc0BEXPPCm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "xO5BzKsAyXUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. 실험 설계 및 방법**\n",
        "## **3-1. DecisionTree**\n",
        "Decision Tree의 경우, Classification을 하는 데에 있어 가장 대표적이면서도, 직관적인 알고리즘이라고 생각하여 선정하였다. criterion을 gini로 설정하는 것보다 entropy로 설정하였을 때 더 성능이 좋게 나온 것을 확인하여 이후 모델에서도 crition을 entropy로 설정한 후 다른 파라미터들에 변화를 주었다. </br>\n",
        "max_depth, min_samples_leaf, min_impurity decrease 와 같은 파라미터에 비해 max_leaf_nodes의 파라미터에 변화를 주는 것이 default 모델 대비 성능 향상이 잘 이루어지는 것을 확인할 수 있었다."
      ],
      "metadata": {
        "id": "M7QWvy-jHF2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "dt1 = DecisionTreeClassifier(random_state=42)\n",
        "print('dt1 score: ', cross_val_score(dt1, x_train, y_train, cv=10).mean())\n",
        "\n",
        "dt2 = DecisionTreeClassifier(criterion=\"entropy\", random_state=42)\n",
        "print('dt2 score: ', cross_val_score(dt2, x_train, y_train, cv=10).mean())\n",
        "\n",
        "dt3 = DecisionTreeClassifier(criterion=\"entropy\", min_samples_leaf=4, random_state=42)\n",
        "print('dt3 score: ', cross_val_score(dt3, x_train, y_train, cv=10).mean())\n",
        "\n",
        "dt4 = DecisionTreeClassifier(criterion=\"entropy\", max_leaf_nodes=30, random_state=42)\n",
        "print('dt4 score: ', cross_val_score(dt4, x_train, y_train, cv=10).mean())\n",
        "\n",
        "dt5 = DecisionTreeClassifier(criterion=\"entropy\", max_leaf_nodes=8, random_state=42)\n",
        "print('dt5 score: ', cross_val_score(dt5, x_train, y_train, cv=10).mean())\n",
        "\n",
        "dt6 = DecisionTreeClassifier(criterion=\"entropy\", max_leaf_nodes=8, max_depth = 3, random_state=42)\n",
        "print('dt6 score: ', cross_val_score(dt6, x_train, y_train, cv=10).mean())\n",
        "\n",
        "dt7 = DecisionTreeClassifier(criterion=\"entropy\", max_leaf_nodes=30, min_impurity_decrease=0.1, random_state=42)\n",
        "print('dt7 score: ', cross_val_score(dt7, x_train, y_train, cv=10).mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_s4K-sap5pAc",
        "outputId": "13f49203-23bd-48b2-e69a-b2f805d7a645"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dt1 score:  0.7936033657812243\n",
            "dt2 score:  0.7965104768190068\n",
            "dt3 score:  0.8072219105758125\n",
            "dt4 score:  0.8390202936809107\n",
            "dt5 score:  0.8435667381620193\n",
            "dt6 score:  0.8406599571027883\n",
            "dt7 score:  0.825758125721828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "파라미터를 달리한 여러개의 모델 중 가장 성능이 좋게 나온 dt5 모델에 대해서 test-set을 이용한 모델 평가를 하였다."
      ],
      "metadata": {
        "id": "LIsYY-Q8LPRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt5.fit(x_train, y_train)\n",
        "print(dt5.score(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA__TiW7C0wr",
        "outputId": "1c88ed64-50db-4ea4-fb5a-8b3df0dd50f8"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8440677966101695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Feature Selection 적용**\n",
        "feature selection 기법으로 **'반복적 특성 선택**'을 사용하였다. \n",
        "특성 선택에 사용한 모델은 Random Forest 이며, n_features_to_select=7로 설정하여 feature이 7개가 남을 때까지 중요도가 낮은 특성을 제거하도록 하였다. 여기서 select 된 feature들은 아래 다른 알고리즘들의 Feature Selection 전, 후 성능을 비교할 때에도 사용 될 예정이다."
      ],
      "metadata": {
        "id": "ba8Sl8KqL-qJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "select = RFE(RandomForestClassifier(n_estimators=100, random_state=42), n_features_to_select=8)\n",
        "select.fit(x_train, y_train)\n",
        "\n",
        "x_new_train = select.transform(x_train)\n",
        "x_new_test = select.transform(x_test)"
      ],
      "metadata": {
        "id": "7nar-9tDiovp"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature selection을 거쳐서 새롭게 만들어진 data set에 대해서 모델 평가를 한다."
      ],
      "metadata": {
        "id": "Yeck3TQBNWo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt5.fit(x_new_train, y_train)\n",
        "print(dt5.score(x_new_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qT2U2lNSL2Ab",
        "outputId": "b7ef5b3b-5484-4fe3-9527-137e58b26f26"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8440677966101695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3-2. RandomForest**\n",
        "위에서 사용한 Decision Tree에서 더 나아가 여러개의 결정트리를 만들어 그 평균 예측치를 사용하면 어느 정도의 성능 향상이 일어날지 확인하기 위해 앙상블 대표 기법인 Random Forest를 사용해 보았다. 몇 개의 결정 트리를 사용할 것인지를 결정하는 n_estimators 파라미터와 위의 Decision Tree 실험에서 성능에 영향을 가장 많이 준 max_leaf_nodes 파라미터를 위주로 변화를 주면서 실험을 진행하였다."
      ],
      "metadata": {
        "id": "1KhHNN-hHNjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf1 = RandomForestClassifier(criterion=\"entropy\", random_state=42)\n",
        "print('rf1 score: ', cross_val_score(rf1, x_train, y_train, cv=10).mean())\n",
        "\n",
        "rf2 = RandomForestClassifier(criterion=\"entropy\", max_leaf_nodes=100, random_state=42)\n",
        "print('rf2 score: ', cross_val_score(rf2, x_train, y_train, cv=10).mean())\n",
        "\n",
        "rf3 = RandomForestClassifier(criterion=\"entropy\", n_estimators=150, random_state=42)\n",
        "print('rf3 score: ', cross_val_score(rf3, x_train, y_train, cv=10).mean())\n",
        "\n",
        "rf4 = RandomForestClassifier(criterion=\"entropy\", n_estimators=150, max_depth = 20, random_state=42)\n",
        "print('rf4 score: ', cross_val_score(rf4, x_train, y_train, cv=10).mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iXIjxGcEIHG",
        "outputId": "1f7fe7fc-229f-4acc-d8be-e17394d08ed2"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rf1 score:  0.8466569872958256\n",
            "rf2 score:  0.8455667381620193\n",
            "rf3 score:  0.8477469064510806\n",
            "rf4 score:  0.8475647582907111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "파라미터를 달리한 여러개의 모델 중 가장 성능이 좋게 나온 rf3 모델에 대해서 test-set을 이용한 모델 평가를 하였다."
      ],
      "metadata": {
        "id": "5tkNbKetT4TQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf3.fit(x_train, y_train)\n",
        "print(rf3.score(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEsoqbn3G6hL",
        "outputId": "10f07f34-d6f9-4567-c66d-61ea6db59cd7"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8567796610169491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Feature Selection 적용**"
      ],
      "metadata": {
        "id": "a0ElMcDxOTu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf3.fit(x_new_train, y_train)\n",
        "print(rf3.score(x_new_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZWRgkdfXZ8K",
        "outputId": "5dfb156a-0cc0-418d-99fd-aa794d356bc9"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8597457627118644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3-3. MLP**\n",
        "실험 데이터의 경우 feature 수가 16개이기 때문에 복잡도가 높고, linearity로 표현할 수 없다. MLP는 여러 layer를 사용하기 때문에 Decision Tree에 비해 경계선이 유연하여 데이터의 non-linearity를 더 잘 표현하고, 그에 따라 classification 성능도 더 좋을 것이라고 생각하여 선정하게 되었다. MLP에서는 hidden layer의 개수를 결정하는 것이 가장 중요하기 때문에 default 모델에 비해 hidden layer 개수를 더 많이 해서 정확도를 높이고자 하였다. 또한 learning_rate와 max_iter의 파라미터를 변경하면서 최적의 모델을 찾고자 하였다."
      ],
      "metadata": {
        "id": "rF0JCVhJHnA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp1 = MLPClassifier(random_state=42)\n",
        "print('mlp1 score: ', cross_val_score(mlp1, x_train, y_train, cv=10).mean())\n",
        "\n",
        "mlp2 = MLPClassifier(hidden_layer_sizes=200, random_state=42)\n",
        "print('mlp2 score: ', cross_val_score(mlp2, x_train, y_train, cv=10).mean())\n",
        "\n",
        "mlp3 = MLPClassifier(hidden_layer_sizes=200, learning_rate_init=0.0005, random_state=42)\n",
        "print('mlp3 score: ', cross_val_score(mlp3, x_train, y_train, cv=10).mean())\n",
        "\n",
        "mlp4 = MLPClassifier(hidden_layer_sizes=200, max_iter=300, random_state=42)\n",
        "print('mlp4 score: ', cross_val_score(mlp4, x_train, y_train, cv=10).mean())\n",
        "\n",
        "mlp5 = MLPClassifier(hidden_layer_sizes=200, learning_rate_init=0.0005, max_iter=300, random_state=42)\n",
        "print('mlp5 score: ', cross_val_score(mlp5, x_train, y_train, cv=10).mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1EL3S3YHuqW",
        "outputId": "9194bb9b-ea61-40c2-ca91-bec8e3ba1f97"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mlp1 score:  0.7883276687015344\n",
            "mlp2 score:  0.7714416762910411\n",
            "mlp3 score:  0.7946906451080681\n",
            "mlp4 score:  0.7714416762910411\n",
            "mlp6 score:  0.7946906451080681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "파라미터를 달리한 여러개의 모델 중 가장 성능이 좋게 나온 mlp3 모델에 대해서 test-set을 이용한 모델 평가를 하였다."
      ],
      "metadata": {
        "id": "q157InngWcDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp3.fit(x_train, y_train)\n",
        "print(mlp3.score(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JhRXatiNmRR",
        "outputId": "809f4f39-2026-45cf-a250-6a4aacc45345"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7533898305084745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Feature Selection 적용**"
      ],
      "metadata": {
        "id": "SZu7fFOGOVmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp3.fit(x_new_train, y_train)\n",
        "print(mlp3.score(x_new_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13goUsLjJn5-",
        "outputId": "9b13fec5-53cd-46fa-a42d-7ef2d6d0c6e7"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8084745762711865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3-4. KNN**\n",
        "고객 중 성향(feature)이 비슷한 고객들은 정기예금을 들지(label)에 대해 비슷한 결정을 내릴 것이라고 생각하여, 유사한 특징을 가지는 데이터들끼리 모아주는 KNN 알고리즘을 선정하게 되었다. KNN의 경우 몇개의 center를 설정할 것인가가 중요한 요인인데, 몇번의 실험을 통해 default 모델(k가 5)에 비해 k를 10으로 설정한 모델이 더 좋은 성능을 보인다는 것을 확인할 수 있었다. 또한 맨해턴 거리, 유클리디안 거리 등 인스턴스끼리의 거리 측정법도 달리하여 실험하였다."
      ],
      "metadata": {
        "id": "1SYeRQvUStPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn1 = KNeighborsClassifier()\n",
        "print('knn1 score: ', cross_val_score(knn1, x_train, y_train, cv=10).mean())\n",
        "\n",
        "knn2 = KNeighborsClassifier(n_neighbors=10)\n",
        "print('knn2 score: ', cross_val_score(knn2, x_train, y_train, cv=10).mean())\n",
        "\n",
        "knn3 = KNeighborsClassifier(p=1)\n",
        "print('knn3 score: ', cross_val_score(knn3, x_train, y_train, cv=10).mean())\n",
        "\n",
        "knn4 = KNeighborsClassifier(n_neighbors=10, p=1)\n",
        "print('knn4 score: ', cross_val_score(knn4, x_train, y_train, cv=10).mean())\n",
        "\n",
        "knn5 = KNeighborsClassifier(n_neighbors=10, p=1, algorithm='ball_tree')\n",
        "print('knn5 score: ', cross_val_score(knn5, x_train, y_train, cv=10).mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJIx7JNzSw1m",
        "outputId": "7013dc11-0494-4516-e47c-3704e47710aa"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "knn1 score:  0.7707101138426002\n",
            "knn2 score:  0.7781616894901832\n",
            "knn3 score:  0.7832453390529616\n",
            "knn4 score:  0.7859722818016829\n",
            "knn5 score:  0.7861540999835012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "파라미터를 달리한 여러개의 모델 중 가장 성능이 좋게 나온 knn5 모델에 대해서 test-set을 이용한 모델 평가를 하였다."
      ],
      "metadata": {
        "id": "NpjaGhNRYQKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn5.fit(x_train, y_train)\n",
        "print(knn5.score(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDVSK1N4bOgY",
        "outputId": "17b36c05-76ca-4eb0-acca-84df543e11af"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7974576271186441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Feature Selection 적용**"
      ],
      "metadata": {
        "id": "InDmr3mNOXI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn5.fit(x_new_train, y_train)\n",
        "print(knn5.score(x_new_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGfCS6gQJupO",
        "outputId": "224e82dd-7208-4450-8c62-d0623cac8e93"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.798728813559322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3-5. AdaBoost**\n",
        "위에서 Decision Tree 알고리즘, Decision Tree에 Bagging 기법을 적용한 Random Forest 알고리즘을 가지고 실험을 진행해보았다. 이번에는 Decision Tree에 Boosting 기법을 적용한 AdaBoost를 선정하였다. Boosting의 경우 올바르게 분류하지 못한 데이터에 더 높은 가중치를 줌으로써 다음 학습에 더 큰 비중을 차지하도록 하므로, 기본 Decision Tree와 Random Forest에 비해 더 좋은 성능을 보일 것으로 예측하였다. Random Forest와 마찬가지로 n_estimators 파라미터와 learning_rate 파라미터를 변경하면서 실험을 진행하였다."
      ],
      "metadata": {
        "id": "z8rDXOgncz0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada1 = AdaBoostClassifier(n_estimators=10, random_state=42)\n",
        "print('ada1 score: ', cross_val_score(ada1, x_train, y_train, cv=10).mean())\n",
        "\n",
        "ada2 = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
        "print('ada2 score: ', cross_val_score(ada2, x_train, y_train, cv=10).mean())\n",
        "\n",
        "ada3 = AdaBoostClassifier(n_estimators=50, learning_rate=0.5, random_state=42)\n",
        "print('ada3 score: ', cross_val_score(ada3, x_train, y_train, cv=10).mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNoq3Bfqc7Oi",
        "outputId": "14d79135-c2a4-4455-eb99-fbcf41d29693"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ada1 score:  0.8452001319914206\n",
            "ada2 score:  0.8473826101303414\n",
            "ada3 score:  0.8510153440026398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "파라미터를 달리한 여러개의 모델 중 가장 성능이 좋게 나온 ada3 모델에 대해서 test-set을 이용한 모델 평가를 하였다."
      ],
      "metadata": {
        "id": "7xrW2CCVZem5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ada3.fit(x_train, y_train)\n",
        "print(ada3.score(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwOEMwHteXyA",
        "outputId": "009f6f63-dfce-41d3-994a-d3097e23bce1"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8542372881355932\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Feature Selection 적용**"
      ],
      "metadata": {
        "id": "8AddhMAJOYaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ada3.fit(x_new_train, y_train)\n",
        "print(ada3.score(x_new_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Iqv3mDrKT6h",
        "outputId": "a4e727d7-2f76-4ecc-99eb-47ed5ce481d1"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8563559322033898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "F_2Ayq4Lyhmx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. 실험 결과 분석**"
      ],
      "metadata": {
        "id": "NfM-dwI2ZlMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "각 알고리즘 별로, 가장 좋은 성능을 보인 모델에 feature selection을 적용하기 전, 후로 나누어 실험 결과를 분석해보았다.</br>\n",
        "\n",
        "\n",
        "### **1.   Decision Tree(84.40% -> 84.40%)**\n",
        "Decision Tree의 경우 알고리즘 자체의 성능은 좋은 편에 속하지만, feature selection을 적용하기 전과 후의 정확도가 둘다 84.40%로 성능 차이가 없었다. 보통 feature selection은 irrelevant하거나 redundant한 feature를 제거해줌으로써 모델의 성능을 높일 수 있도록 해주는데, 이 경우 모든 feature들이 Decision Tree를 구성하는 데에 있어 유의미하게 사용되어 성능 차이가 없는 것으로 생각할 수 있다. </br>\n",
        "</br>\n",
        "\n",
        "### **2.   Random Forest(85.67% -> 85.97%)**\n",
        "Random Forest의 경우 기본 Decision Tree에 비해 약간 더 높은 성능을 보였다. 하나의 결정트리만을 이용하면 data set의 성향에 따라 과적합이나 편중된 예측을 할 가능성이 있는데, Random Forest는 여려개 결정트리의 예측 중 과반수 결과를 사용하기 때문에 위의 위험성을 줄일 수 있다. 그러한 점에서 하나의 Decision Tree에 비해 더 성능이 좋게 나온 것으로 예측한다. 또한 Feature Selection을 적용하였을 때 약간의 성능 향상을 보였다. 여러개의 결정트리의 예측값을 사용하다보면 예측모델 자체가 복잡해질 수 밖에 없는데, 이때 feature space의 복잡도를 줄이는 방법(Feature Selection)이 예측모델의 복잡도를 줄여줌으로써 성능을 높인 것으로 예측할 수 있다. </br>\n",
        "</br>\n",
        "\n",
        "### **3.   MLP(75.33% -> 80.84%)**\n",
        "MLP는 실험에 사용한 모든 모델 중 가장 낮은 정확도를 보였다. 실험에서 cross-validation score을 높이기 위해 hidden layer의 개수를 100개에서 200개로 늘였는데 이로 인해 약간의 과적합이 발생한 것으로 예상한다. 따라서 test set으로 평가했을 때는 75.33%으로 정확도가 가장 낮았지만, feature selection을 적용한 후 다른 모델들에 비해 가장 유의미한 성능 차이를 보였다. 여러 개의 hidden layer을 적용함으로써 생긴 과적합, 복잡성이 feature selection 적용으로 인해 완화된 것으로 예측할 수 있다. </br>\n",
        "</br>\n",
        "\n",
        "### **4.   KNN(79.74% -> 79.87%)**\n",
        "KNN은 79.84% -> 79.87% 의 정확도를 보였다. 다른 모델들에 비해 낮은 성능을 보인 원인은 데이터 셋의 특성에 있다고 생각한다. 실험에 이용 된 데이터 셋의 경우 feature이 16개나 되고, 그 feature들 중에는 데이터 전처리 과정에서 원래 범주형 데이터였던 것을 수치형 데이터로 변환해준 feature들이 다수 존재한다. 이렇게 변환 된 feature들의 값은 범주에 따라 임의로 설정 된 수치값일 뿐이지, 수치값의 차이가 크다(예를 들어, 1과 3의 차이가 보다 1과 7의 차이가 더 크다)고 해서 범주의 차이가 크다는 것을 의미하지는 않는다. 이러한 점에서 범주형 데이터가 많은 데이터에서 인스턴스끼리의 유사도는 측정하기 어려우므로 다른 모델들에 비해 낮은 성능을 보였다고 생각한다. 범주형 데이터를 바이너리 데이터로 변환해주었으면 더 높은 성능을 보였을 것이라고 생각한다. </br>\n",
        "</br>\n",
        "\n",
        "### **5.   AdaBoost(85.42% -> 85.63%)**\n",
        "AdaBoost의 경우 Random Forest와 거의 비슷한 성능을 보였다. AdaBoost는 잘 못 예측한 인스턴스에 더 높은 가중치를 주어 다음 학습 때 이용하므로 성능이 더 좋을 것이라고 예상했는데, 이미 Random Forest가 주어진 데이터 셋에 대하여 높은 성능을 보였기 때문에, 즉 잘 못 예측하는 인스턴스가 적기 때문에 거의 비슷한 성능을 보였다고 생각한다. 오히려 Random Forest에 비해 살짝 낮은 성능을 보이는 것은 n_estimators, learning rate와 같은 파라미터에서 차이가 있었기 때문이라고 예측한다. Feature Selection을 적용하였을 때에는 다른 모델들과 마찬가지로 약간의 성능 향상을 보였고, 모델이 데이터 셋을 학습하는 데 있어 불필요한 feature들을 제거함으로써 성능이 향상된 것으로 보인다.\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bIdBshN4ZwY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. 결론**"
      ],
      "metadata": {
        "id": "FFT0E5bdrX7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 실험에서는 고객의 Bank Marketing에 대한 데이터를 가지고 고객이 정기예금에 가입할 것인지를 예측하는 Classification 모델을 설계하였다. </br>\n",
        "실험을 진행하기에 앞서 범주형 데이터 -> 수치형 데이터 변환, 무의미한 수치값을 갖는 인스턴스 제거 등을 수행하면서 모델이 데이터를 더 잘 학습할 수 있도록 데이터 전처리 과정을 거쳤다.\n",
        "Decision Tree, Random Forest, MLP, KNN, AdaBoost 5가지 알고리즘을 사용하여 실험을 진행하였고 각 알고리즘에 대해 파라미터를 변경하면서 높은 성능을 보이는 모델을 선별하였고, 선별 된 모델에 대해서는 feature selection을 적용한 결과값도 도출하였다. 5개의 알고리즘 중에서 Random Forest가 feature selection 적용 전, 후 둘다 가장 높은 성능을 보였다. 범주형 데이터가 많이 포함 된 데이터 셋의 특징을 고려하면 MLP, KNN과 같은 알고리즘보다 Decision Tree가 더 좋은 성능을 낸 결과를 납득할 수 있다. 또한 한가지 Decision Tree보다는 여러개의 Decision Tree의 결과를 종합하는 것이 더 보편적인 예측값을 낼 수 있으므로 위 실험에서 Random Forest가 가장 높은 성능을 보인 결과를 이해할 수 있다."
      ],
      "metadata": {
        "id": "pyZ-pCXCrhb_"
      }
    }
  ]
}